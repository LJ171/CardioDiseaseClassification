{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method provides a preprocessed data set.\n",
    "\n",
    "Parameters:\n",
    "handle_missing_data (str): describes how to handle missing data, possible values are: \n",
    "    rr - remove rows with missing data\n",
    "    rc - remove columns with missing data\n",
    "    uu - use unknown as its own value \n",
    "    dn - do nothing, in this case onehot encoding isn't possible (replaces missing values with np.nan)\n",
    "         and it only should be used if the prediction algorithm can handle missing data/ None values\n",
    "         \n",
    "use_one_hot_encoding (bool): describes whether one hot encoding should be applied, possible values are:\n",
    "    True  - one hot encoding will be applied\n",
    "    False - one hot encoding won't be applied, but categorical values will be converted to numeric ones\n",
    "    \n",
    "split_size tuple(numeric, numeric, numeric): describes which porportion of the data should be used for the split, possible values:\n",
    "    the input should be tuple with three numeric values which sum up to 1\n",
    "        -> (0.7, 0.2, 0.1) in this case 70% will be used for training, 20% for validation and 10% for testing\n",
    "    In case you want to use more complex cross validation algorithms like k-fold you should only split into train\n",
    "    and apply your cross validation algorithm to the train data\n",
    "    \n",
    "Returns: \n",
    "y_train (df): train set (y)\n",
    "x_train (df): train set (x)\n",
    "y_val   (df): validation set (y)\n",
    "x_val   (df): validation set (x)\n",
    "y_test  (df): test set (y)\n",
    "x_test  (df): test set (x)\n",
    "\"\"\"\n",
    "def get_data(handle_missing_data, use_one_hot_encoding, split_size):\n",
    "    # load the data\n",
    "    data_file_folder = 'data'\n",
    "    data_file_name = 'retrieved_data.csv' \n",
    "    data_df = pd.read_csv(os.path.join('..' , data_file_folder, data_file_name), dtype='category')\n",
    "            \n",
    "    # drop unnecessary columns from x\n",
    "    data_df = data_df.drop(['veil-type'], axis=1)\n",
    "    \n",
    "    # handle missing values\n",
    "    if handle_missing_data is 'rr':\n",
    "        data_df = data_df[data_df['stalk-root'] != 0]\n",
    "    elif handle_missing_data is 'rc':\n",
    "        data_df = data_df.drop(['stalk-root'], axis=1)\n",
    "    elif handle_missing_data is 'uu':\n",
    "        data_df['stalk-root'] = data_df['stalk-root'].replace('?', 'u').astype('category')\n",
    "    elif handle_missing_data is 'dn':\n",
    "        data_df['stalk-root'] = data_df['stalk-root'].replace('?', np.nan).astype('category')\n",
    "    \n",
    "    # encoding       \n",
    "    if use_one_hot_encoding is True:\n",
    "        # the y column should never be one hot encoded but encoded to numeric values instead\n",
    "        class_df = data_df.drop(data_df.columns.difference(['class']), axis=1)\n",
    "        class_df['class'] = class_df['class'].cat.codes\n",
    "        \n",
    "        data_df = class_df.join(pd.get_dummies(data_df.drop(['class'], axis=1)))        \n",
    "    else:\n",
    "        for (columnName, columnData) in data_df.iteritems(): \n",
    "            data_df[columnName] = data_df[columnName].cat.codes\n",
    "            \n",
    "    # train/ validation/ test split\n",
    "    train, val, test = np.split(data_df.sample(frac=1, random_state=42), [int(split_size[0]*len(data_df)), int((split_size[0] + split_size[1])*len(data_df))])\n",
    "    \n",
    "    # split in x and y         \n",
    "    y_train = train.drop(train.columns.difference(['class']), axis=1)    \n",
    "    x_train = train.drop(['class'], axis=1)\n",
    "    \n",
    "    y_val = val.drop(val.columns.difference(['class']), axis=1)    \n",
    "    x_val = val.drop(['class'], axis=1)\n",
    "        \n",
    "    y_test = test.drop(test.columns.difference(['class']), axis=1)    \n",
    "    x_test = test.drop(['class'], axis=1)\n",
    "    \n",
    "    return y_train, x_train, y_val, x_val, y_test, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
