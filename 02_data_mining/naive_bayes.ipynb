{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data Evaluation notebook once to import the show_evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refernce to data_evaluation notebook to use the show_evaluation function\n",
    "%run data_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Improvement Ideas\n",
    "\"\"\"\n",
    "This method provides a preprocessed data set.\n",
    "\n",
    "Parameters:\n",
    "enable_feature_engineering_gender (bool): describes whether the gender column (categorical) gets replaced by is_female (bool)\n",
    "    True - enabled\n",
    "    False - disabled\n",
    "    \n",
    "enable_feature_engineering_height_weight (bool): describes whether the height and weight column get replaced by bmi \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "    \n",
    "enable_feature_engineering_gluc_chol (bool): describes whether the gluc and chol column get replaced by known_health_issues \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "    \n",
    "enable_feature_engineering_alco_smoking (bool): describes whether the alcohol and smoking column get replaced by unhealthy_lifestyle \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "        \n",
    "enable_outlier_handling (bool): describes whether some extreme data entries will be deleted or not, possbible values:\n",
    "    True - enabled\n",
    "    False - disabled\n",
    "    \n",
    "normalize (str): describes whether the numeric values should be normalized (between 0 and 1), possible values:\n",
    "    'minmax' - uses min max to normalize the data\n",
    "    'median' - uses median to normalize the data\n",
    "    None - data won't be normalized\n",
    "\n",
    "use_one_hot_encoding (bool): describes whether one hot encoding should be applied to categorical data, possible values are:\n",
    "    True  - enabled\n",
    "    False - disabled\n",
    "    \n",
    "split_size tuple(numeric, numeric, numeric): describes which porportion of the data should be used for the split, possible values:\n",
    "    the input should be tuple with three numeric values which sum up to 1\n",
    "        -> (0.7, 0.2, 0.1) in this case 70% will be used for training, 20% for validation and 10% for testing\n",
    "    In case you want to use more complex cross validation algorithms like k-fold you should only split into train\n",
    "    and apply your cross validation algorithm to the train data\n",
    "    \n",
    "Returns: \n",
    "(df): train set (y)\n",
    "(df): train set (x)\n",
    "(df): validation set (y)\n",
    "(df): validation set (x)\n",
    "(df): test set (y)\n",
    "(df): test set (x)\n",
    "\"\"\"\n",
    "def get_data(enable_feature_engineering_gender, enable_feature_engineering_height_weight, enable_feature_engineering_gluc_chol, enable_feature_engineering_alco_smoking, enable_outlier_handling, normalize, enable_one_hot_encoding, split_size):\n",
    "    # load the data\n",
    "    data_file_folder = 'data'\n",
    "    data_file_name = 'cardio_data.csv' \n",
    "    data_df = pd.read_csv(os.path.join('..' , data_file_folder, data_file_name), sep=';')       \n",
    "      \n",
    "    # drop unnecessary columns\n",
    "    data_df = data_df.drop(['id'], axis=1)   \n",
    "            \n",
    "    # set dtypes\n",
    "    data_df = data_df.astype({\n",
    "        'age': 'int64',\n",
    "        'gender': 'int64',\n",
    "        'height': 'int64',\n",
    "        'weight': 'int64',\n",
    "        'ap_hi': 'int64',\n",
    "        'ap_lo': 'int64',\n",
    "        'cholesterol': 'int64',\n",
    "        'gluc': 'int64',\n",
    "        'smoke': 'bool',\n",
    "        'alco': 'bool',\n",
    "        'active': 'bool',\n",
    "        'cardio': 'bool'\n",
    "    })\n",
    "    \n",
    "    # drop duplicate rows\n",
    "    before = data_df.shape[0]\n",
    "    data_df.drop_duplicates(inplace=True)\n",
    "    after = data_df.shape[0]\n",
    "    print(f'Dropped {before - after} duplicate rows.')\n",
    "    \n",
    "    # outlier handline\n",
    "    if enable_outlier_handling:\n",
    "        # remove extreme cases of height, weight and blood presure (height, weight, ap_hi, ap_lo)\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['height'] > 150]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> height too low.')\n",
    "        \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['height'] < 250]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> height too high.')\n",
    "        \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['weight'] > 35]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> weight too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['weight'] < 250]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> weight too high.')\n",
    "       \n",
    "        # normal systolic blood preasure ranges from ~80 to ~120 but values till 240(?) are imaginable                    \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_hi'] > 40]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> systolic bp too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_hi'] < 240]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> systolic bp too high.')\n",
    "        \n",
    "        # normal diastolic blood preasure ranges from ~40 to ~80  but values till 200(?) are imaginable\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] > 20]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> diastolic bp too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] < 220]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> diastolic bp too high.')\n",
    "        \n",
    "        # systolic blood preasure should always be higher then diastolic\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] < data_df['ap_hi']]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> sytolic bp was lower than diastolic.')\n",
    "        \n",
    "    # feature engineering\n",
    "    if enable_feature_engineering_gender:\n",
    "        # replace gender with is female\n",
    "        data_df['is_female'] = data_df['gender'] == 1\n",
    "        data_df.drop(['gender'], axis=1, inplace=True)\n",
    "        \n",
    "    if enable_feature_engineering_height_weight:\n",
    "        # combine height and weight to BMI to reduce the multicollinearity problem\n",
    "        data_df['bmi'] = data_df['weight']/(data_df['height']**2)\n",
    "        data_df.drop(['height', 'weight'], axis=1, inplace=True)\n",
    "        data_df = data_df.astype({'bmi': 'int64'})\n",
    "        \n",
    "    if enable_feature_engineering_alco_smoking:\n",
    "        # combine alcohol and smoking to unhealthy_lifestyle\n",
    "        data_df['unhealthy_lifestyle'] = data_df['alco'] + data_df['smoke'] < 0\n",
    "        data_df.drop(['alco', 'smoke'], axis=1, inplace=True)\n",
    "        \n",
    "    if enable_feature_engineering_gluc_chol:\n",
    "        # combine gluc and cholesterol to known_health_issues\n",
    "        data_df['known_health_issues'] = data_df['gluc'] + data_df['cholesterol'] - 1\n",
    "        data_df.drop(['gluc', 'cholesterol'], axis=1, inplace=True)\n",
    "        \n",
    "    #transforming the blood pressures values into categorical values low, normal, high \n",
    "    data_df['ap_lo_cat'] = pd.Series(np.random.randn(len(data_df['ap_lo'])), index=data_df.index)\n",
    "    data_df['ap_hi_cat'] = pd.Series(np.random.randn(len(data_df['ap_hi'])), index=data_df.index)\n",
    "    \n",
    "    #diastolic blood pressure\n",
    "    j = 0\n",
    "    x = 0\n",
    "    for i in data_df['ap_lo']:\n",
    "        \n",
    "        print(i)\n",
    "        if i <40:\n",
    "            data_df[['ap_lo_cat',j]]='low'\n",
    "        elif i>=40 and i<=80:\n",
    "            data_df[['ap_lo_cat',j]]='normal' \n",
    "        else:\n",
    "            data_df[['ap_lo_cat',j]]='high'\n",
    "        j=j+1\n",
    "    \n",
    "           \n",
    "    #syastolic blood pressure\n",
    "    for i in data_df['ap_hi']:\n",
    "        if i <80:\n",
    "            data_df[['ap_hi_cat',j]]='low'\n",
    "        elif i>=80 and i<=120:\n",
    "            data_df[['ap_hi_cat',j]]='normal'\n",
    "        else:\n",
    "            data_df[['ap_hi_cat',j]]='high'\n",
    "        x=x+1\n",
    "    \n",
    "    #drop the blood pressure columns with the numerical values\n",
    "    #data_df.drop('ap_lo','ap_hi')\n",
    "    \n",
    "    print('whats a breakpoint')\n",
    "                    \n",
    "    print(data_df['ap_lo_cat'])\n",
    "    print(data_df['ap_hi_cat'])\n",
    "            \n",
    "    \n",
    "    # normalization\n",
    "    if normalize is None:\n",
    "        pass    \n",
    "    elif normalize in ['minmax']:\n",
    "        columns_to_normalize = ['age']\n",
    "        \n",
    "        if not enable_feature_engineering_height_weight:\n",
    "            columns_to_normalize.append('height')\n",
    "            columns_to_normalize.append('weight')\n",
    "        else:\n",
    "            columns_to_normalize.append('bmi')\n",
    "        \n",
    "        for column_name in columns_to_normalize:\n",
    "            if normalize == 'minmax':\n",
    "                data_df[column_name] = ((data_df[column_name] - data_df[column_name].min()) / (data_df[column_name].max() - data_df[column_name].min())).astype('float64')\n",
    "    else:\n",
    "        raise Exception('Invalid value for normalization!')\n",
    "        \n",
    "\n",
    "    \n",
    "     # encoding (0 corresponds to healthy and 1 to having a cardio disease)       \n",
    "    # this part also splits in x and y, it was convienient to do at one step\n",
    "    if enable_one_hot_encoding is True:\n",
    "        # the y column should never be one hot encoded but encoded to numeric values instead\n",
    "        \n",
    "        \n",
    "        if enable_feature_engineering_gluc_chol:\n",
    "            columns_to_encode = ['known_health_issues']\n",
    "        else:\n",
    "            columns_to_encode = ['cholesterol', 'gluc']\n",
    "        \n",
    "        y = data_df['cardio']   \n",
    "        x = pd.get_dummies(data_df.drop(['cardio'], axis=1), columns=columns_to_encode)\n",
    "    else:               \n",
    "        # split in x and y         \n",
    "        y = data_df.drop(data_df.columns.difference(['cardio']), axis=1)    \n",
    "        x = data_df.drop(['cardio'], axis=1)\n",
    "    \n",
    "    \n",
    "    # train/ validation/ test split\n",
    "    x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(x, y, test_size = split_size[1] + split_size[2], random_state=42)\n",
    "    \n",
    "    if split_size[1] > 0.0:\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=(split_size[2]/(split_size[1]+split_size[2])), random_state=42)\n",
    "    else:\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "        x_test = x_val_and_test\n",
    "        y_test = y_val_and_test        \n",
    "        \n",
    "    return y_train, x_train, y_val, x_val, y_test, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for get_data function\n",
    "enable_feature_engineering_gender = True\n",
    "enable_feature_engineering_height_weight = True\n",
    "enable_feature_engineering_gluc_chol = False\n",
    "enable_feature_engineering_alco_smoking = True\n",
    "enable_outlier_handling = True\n",
    "normalize = 'minmax'\n",
    "use_one_hot_encoding = False\n",
    "split_size = (0.8, 0.0, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 24 duplicate rows.\n",
      "Dropped 2588 rows -> height too low.\n",
      "Dropped 1 rows -> height too high.\n",
      "Dropped 13 rows -> weight too low.\n",
      "Dropped 0 rows -> weight too high.\n",
      "Dropped 183 rows -> systolic bp too low.\n",
      "Dropped 46 rows -> systolic bp too high.\n",
      "Dropped 38 rows -> diastolic bp too low.\n",
      "Dropped 904 rows -> diastolic bp too high.\n",
      "Dropped 98 rows -> sytolic bp was lower than diastolic.\n",
      "80\n",
      "90\n",
      "70\n",
      "100\n",
      "60\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "60\n",
      "80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besitzer\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:201: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "85\n",
      "60\n",
      "90\n",
      "100\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "70\n",
      "85\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "90\n",
      "60\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "60\n",
      "100\n",
      "100\n",
      "90\n",
      "90\n",
      "90\n",
      "60\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "100\n",
      "70\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "85\n",
      "70\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "60\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "100\n",
      "90\n",
      "90\n",
      "100\n",
      "89\n",
      "70\n",
      "70\n",
      "110\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "65\n",
      "80\n",
      "110\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "89\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "100\n",
      "80\n",
      "80\n",
      "70\n",
      "85\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "63\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "100\n",
      "70\n",
      "90\n",
      "65\n",
      "70\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "79\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "70\n",
      "100\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "100\n",
      "90\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "60\n",
      "100\n",
      "90\n",
      "90\n",
      "60\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "110\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "79\n",
      "70\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "79\n",
      "80\n",
      "89\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "100\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "120\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "70\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "90\n",
      "100\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "60\n",
      "70\n",
      "60\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "30\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "109\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "90\n",
      "70\n",
      "84\n",
      "80\n",
      "80\n",
      "90\n",
      "60\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "100\n",
      "60\n",
      "80\n",
      "80\n",
      "90\n",
      "50\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "91\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "70\n",
      "40\n",
      "80\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "100\n",
      "90\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "70\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "90\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "70\n",
      "70\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "80\n",
      "70\n",
      "70\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "70\n",
      "110\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "100\n",
      "90\n",
      "100\n",
      "90\n",
      "80\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "80\n",
      "79\n",
      "80\n",
      "90\n",
      "80\n",
      "100\n",
      "70\n",
      "90\n",
      "60\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "110\n",
      "90\n",
      "100\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "85\n",
      "60\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "70\n",
      "100\n",
      "90\n",
      "60\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "73\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "100\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "90\n",
      "70\n",
      "70\n",
      "100\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "79\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "60\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "78\n",
      "110\n",
      "90\n",
      "80\n",
      "90\n",
      "100\n",
      "100\n",
      "70\n",
      "100\n",
      "84\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "110\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "75\n",
      "90\n",
      "100\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "75\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "110\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "60\n",
      "70\n",
      "90\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "60\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "100\n",
      "100\n",
      "80\n",
      "70\n",
      "75\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "100\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "60\n",
      "60\n",
      "100\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "85\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "87\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "60\n",
      "90\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "100\n",
      "60\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "60\n",
      "80\n",
      "100\n",
      "90\n",
      "70\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "100\n",
      "70\n",
      "86\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "100\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "100\n",
      "80\n",
      "82\n",
      "90\n",
      "85\n",
      "90\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "70\n",
      "80\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "80\n",
      "85\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "95\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "100\n",
      "80\n",
      "90\n",
      "60\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "79\n",
      "90\n",
      "90\n",
      "80\n",
      "74\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "100\n",
      "90\n",
      "70\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "82\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "70\n",
      "90\n",
      "97\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "75\n",
      "65\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "100\n",
      "80\n",
      "70\n",
      "70\n",
      "70\n",
      "90\n",
      "60\n",
      "90\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "100\n",
      "100\n",
      "80\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "110\n",
      "80\n",
      "90\n",
      "100\n",
      "60\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "60\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "70\n",
      "90\n",
      "100\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "120\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "70\n",
      "80\n",
      "60\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "85\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "110\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "80\n",
      "100\n",
      "90\n",
      "80\n",
      "70\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "70\n",
      "70\n",
      "90\n",
      "80\n",
      "70\n",
      "90\n",
      "120\n",
      "90\n",
      "70\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "90\n",
      "80\n",
      "80\n",
      "70\n",
      "90\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "100\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "60\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "70\n",
      "80\n",
      "80\n",
      "90\n",
      "90\n",
      "80\n",
      "90\n",
      "80\n",
      "80\n",
      "80\n",
      "90\n",
      "80\n",
      "100\n",
      "80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5e5f61f897c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#apply get_data function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menable_feature_engineering_gender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_feature_engineering_height_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_feature_engineering_gluc_chol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_feature_engineering_alco_smoking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_outlier_handling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_one_hot_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-a9bf9b543bdc>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(enable_feature_engineering_gender, enable_feature_engineering_height_weight, enable_feature_engineering_gluc_chol, enable_feature_engineering_alco_smoking, enable_outlier_handling, normalize, enable_one_hot_encoding, split_size)\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ap_lo_cat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'low'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m40\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ap_lo_cat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ap_lo_cat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'high'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3035\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3036\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3037\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3070\u001b[0m                 )[1]\n\u001b[0;32m   3071\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3072\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m         \u001b[1;31m# maybe partial set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1542\u001b[1;33m         \u001b[0mtake_split_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \u001b[1;31m# if there is only one block/type, still have to take split path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5237\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5238\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_inplace_setting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5198\u001b[0m         \"\"\"\n\u001b[0;32m   5199\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5200\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5202\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5235\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5237\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5238\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[1;32m-> 1900\u001b[1;33m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1901\u001b[0m         )\n\u001b[0;32m   1902\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1922\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#apply get_data function\n",
    "y_train, x_train, y_val, x_val, y_test, x_test = get_data(enable_feature_engineering_gender, enable_feature_engineering_height_weight, enable_feature_engineering_gluc_chol, enable_feature_engineering_alco_smoking, enable_outlier_handling, normalize, use_one_hot_encoding, split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the model (predict)\n",
    "y_prob = naive_bayes.predict(x_test)\n",
    "y_pred = np.round(y_prob)\n",
    "y_proba = naive_bayes.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(y_test, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "method_name = 'Naïve Bayes'\n",
    "predicted_probabilities = y_proba\n",
    "savePredictedProbabilities(method_name, y_test, predicted_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
