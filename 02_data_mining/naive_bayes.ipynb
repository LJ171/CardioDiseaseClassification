{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data Evaluation notebook once to import the show_evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refernce to data_evaluation notebook to use the show_evaluation function\n",
    "%run data_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Improvement Ideas\n",
    "\"\"\"\n",
    "This method provides a preprocessed data set.\n",
    "\n",
    "Parameters:\n",
    "enable_feature_engineering_gender (bool): describes whether the gender column (categorical) gets replaced by is_female (bool)\n",
    "    True - enabled\n",
    "    False - disabled\n",
    "    \n",
    "enable_feature_engineering_height_weight (bool): describes whether the height and weight column get replaced by bmi \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "    \n",
    "enable_feature_engineering_gluc_chol (bool): describes whether the gluc and chol column get replaced by known_health_issues \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "    \n",
    "enable_feature_engineering_alco_smoking (bool): describes whether the alcohol and smoking column get replaced by unhealthy_lifestyle \n",
    "    True - enabled\n",
    "    False - disabled  \n",
    "        \n",
    "enable_outlier_handling (bool): describes whether some extreme data entries will be deleted or not, possbible values:\n",
    "    True - enabled\n",
    "    False - disabled\n",
    "    \n",
    "normalize (str): describes whether the numeric values should be normalized (between 0 and 1), possible values:\n",
    "    'minmax' - uses min max to normalize the data\n",
    "    'median' - uses median to normalize the data\n",
    "    None - data won't be normalized\n",
    "\n",
    "use_one_hot_encoding (bool): describes whether one hot encoding should be applied to categorical data, possible values are:\n",
    "    True  - enabled\n",
    "    False - disabled\n",
    "    \n",
    "split_size tuple(numeric, numeric, numeric): describes which porportion of the data should be used for the split, possible values:\n",
    "    the input should be tuple with three numeric values which sum up to 1\n",
    "        -> (0.7, 0.2, 0.1) in this case 70% will be used for training, 20% for validation and 10% for testing\n",
    "    In case you want to use more complex cross validation algorithms like k-fold you should only split into train\n",
    "    and apply your cross validation algorithm to the train data\n",
    "    \n",
    "Returns: \n",
    "(df): train set (y)\n",
    "(df): train set (x)\n",
    "(df): validation set (y)\n",
    "(df): validation set (x)\n",
    "(df): test set (y)\n",
    "(df): test set (x)\n",
    "\"\"\"\n",
    "def get_data(enable_feature_engineering_gender, enable_feature_engineering_height_weight, enable_feature_engineering_gluc_chol, enable_feature_engineering_alco_smoking, enable_outlier_handling, normalize, enable_one_hot_encoding, split_size):\n",
    "    # load the data\n",
    "    data_file_folder = 'data'\n",
    "    data_file_name = 'cardio_data.csv' \n",
    "    data_df = pd.read_csv(os.path.join('..' , data_file_folder, data_file_name), sep=';')       \n",
    "      \n",
    "    # drop unnecessary columns\n",
    "    data_df = data_df.drop(['id'], axis=1)   \n",
    "            \n",
    "    # set dtypes\n",
    "    data_df = data_df.astype({\n",
    "        'age': 'int64',\n",
    "        'gender': 'int64',\n",
    "        'height': 'int64',\n",
    "        'weight': 'int64',\n",
    "        'ap_hi': 'int64',\n",
    "        'ap_lo': 'int64',\n",
    "        'cholesterol': 'int64',\n",
    "        'gluc': 'int64',\n",
    "        'smoke': 'bool',\n",
    "        'alco': 'bool',\n",
    "        'active': 'bool',\n",
    "        'cardio': 'bool'\n",
    "    })\n",
    "    \n",
    "    # drop duplicate rows\n",
    "    before = data_df.shape[0]\n",
    "    data_df.drop_duplicates(inplace=True)\n",
    "    after = data_df.shape[0]\n",
    "    print(f'Dropped {before - after} duplicate rows.')\n",
    "    \n",
    "    # outlier handline\n",
    "    if enable_outlier_handling:\n",
    "        # remove extreme cases of height, weight and blood presure (height, weight, ap_hi, ap_lo)\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['height'] > 150]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> height too low.')\n",
    "        \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['height'] < 250]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> height too high.')\n",
    "        \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['weight'] > 35]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> weight too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['weight'] < 250]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> weight too high.')\n",
    "       \n",
    "        # normal systolic blood preasure ranges from ~80 to ~120 but values till 240(?) are imaginable                    \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_hi'] > 40]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> systolic bp too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_hi'] < 240]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> systolic bp too high.')\n",
    "        \n",
    "        # normal diastolic blood preasure ranges from ~40 to ~80  but values till 200(?) are imaginable\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] > 20]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> diastolic bp too low.')\n",
    "                \n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] < 220]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> diastolic bp too high.')\n",
    "        \n",
    "        # systolic blood preasure should always be higher then diastolic\n",
    "        before = data_df.shape[0]\n",
    "        data_df = data_df[data_df['ap_lo'] < data_df['ap_hi']]\n",
    "        after = data_df.shape[0]\n",
    "        \n",
    "        print(f'Dropped {before - after} rows -> sytolic bp was lower than diastolic.')\n",
    "        \n",
    "    # feature engineering\n",
    "    if enable_feature_engineering_gender:\n",
    "        # replace gender with is female\n",
    "        data_df['is_female'] = data_df['gender'] == 1\n",
    "        data_df.drop(['gender'], axis=1, inplace=True)\n",
    "        \n",
    "    if enable_feature_engineering_height_weight:\n",
    "        # combine height and weight to BMI to reduce the multicollinearity problem\n",
    "        data_df['bmi'] = data_df['weight']/(data_df['height']**2)\n",
    "        data_df.drop(['height', 'weight'], axis=1, inplace=True)\n",
    "        data_df = data_df.astype({'bmi': 'int64'})\n",
    "        \n",
    "    if enable_feature_engineering_alco_smoking:\n",
    "        # combine alcohol and smoking to unhealthy_lifestyle\n",
    "        data_df['unhealthy_lifestyle'] = data_df['alco'] + data_df['smoke'] < 0\n",
    "        data_df.drop(['alco', 'smoke'], axis=1, inplace=True)\n",
    "        \n",
    "    if enable_feature_engineering_gluc_chol:\n",
    "        # combine gluc and cholesterol to known_health_issues\n",
    "        data_df['known_health_issues'] = data_df['gluc'] + data_df['cholesterol'] - 1\n",
    "        data_df.drop(['gluc', 'cholesterol'], axis=1, inplace=True)\n",
    "    \n",
    "    #transforming the blood pressures values into categorical values low, normal, high \n",
    "    data_df['ap_lo_cat'] = pd.Series(np.random.randn(len(data_df['ap_lo'])), index=data_df.index)\n",
    "    data_df['ap_hi_cat'] = pd.Series(np.random.randn(len(data_df['ap_hi'])), index=data_df.index)\n",
    "    \n",
    "    cut_labels = ['low', 'normal', 'high']\n",
    "    cut_bins = [0, 40, 80, data_df['ap_lo'].max()]\n",
    "    data_df['ap_lo_cat'] = pd.cut(data_df['ap_lo'], bins=cut_bins, labels=cut_labels)\n",
    "        \n",
    "    print(data_df['ap_lo_cat'])\n",
    "    \n",
    "    cut_labels = ['low', 'normal', 'high']\n",
    "    cut_bins = [0, 80, 120, data_df['ap_hi'].max() ]\n",
    "    data_df['ap_hi_cat'] = pd.cut(data_df['ap_hi'], bins=cut_bins, labels=cut_labels)\n",
    "        \n",
    "    print(data_df['ap_hi_cat'])\n",
    "    \n",
    "    data_df.drop(['ap_lo', 'ap_hi'], axis=1, inplace=True)\n",
    "    data_df = data_df.astype({'ap_lo_cat': 'str'})\n",
    "    data_df = data_df.astype({'ap_hi_cat': 'str'})\n",
    "    \n",
    "\n",
    "    # normalization\n",
    "    if normalize is None:\n",
    "        pass    \n",
    "    elif normalize in ['minmax']:\n",
    "        columns_to_normalize = ['age']\n",
    "        \n",
    "        if not enable_feature_engineering_height_weight:\n",
    "            columns_to_normalize.append('height')\n",
    "            columns_to_normalize.append('weight')\n",
    "        \n",
    "        for column_name in columns_to_normalize:\n",
    "            if normalize == 'minmax':\n",
    "                data_df[column_name] = ((data_df[column_name] - data_df[column_name].min()) / (data_df[column_name].max() - data_df[column_name].min())).astype('float64')\n",
    "    else:\n",
    "        raise Exception('Invalid value for normalization!')\n",
    "        \n",
    "\n",
    "    \n",
    "     # encoding (0 corresponds to healthy and 1 to having a cardio disease)       \n",
    "    # this part also splits in x and y, it was convienient to do at one step\n",
    "    if enable_one_hot_encoding is True:\n",
    "        # the y column should never be one hot encoded but encoded to numeric values instead\n",
    "        \n",
    "        \n",
    "        if enable_feature_engineering_gluc_chol:\n",
    "            columns_to_encode = ['known_health_issues']\n",
    "        else:\n",
    "            columns_to_encode = ['cholesterol', 'gluc']\n",
    "        \n",
    "        y = data_df['cardio']   \n",
    "        x = pd.get_dummies(data_df.drop(['cardio'], axis=1), columns=columns_to_encode)\n",
    "    else:               \n",
    "        # split in x and y         \n",
    "        y = data_df.drop(data_df.columns.difference(['cardio']), axis=1)    \n",
    "        x = data_df.drop(['cardio'], axis=1)\n",
    "    \n",
    "    \n",
    "    # train/ validation/ test split\n",
    "    x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(x, y, test_size = split_size[1] + split_size[2], random_state=42)\n",
    "    \n",
    "    if split_size[1] > 0.0:\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=(split_size[2]/(split_size[1]+split_size[2])), random_state=42)\n",
    "    else:\n",
    "        x_val = None\n",
    "        y_val = None\n",
    "        x_test = x_val_and_test\n",
    "        y_test = y_val_and_test        \n",
    "        \n",
    "    return y_train, x_train, y_val, x_val, y_test, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for get_data function\n",
    "enable_feature_engineering_gender = True\n",
    "enable_feature_engineering_height_weight = True\n",
    "enable_feature_engineering_gluc_chol = False\n",
    "enable_feature_engineering_alco_smoking = True\n",
    "enable_outlier_handling = True\n",
    "normalize = 'minmax'\n",
    "use_one_hot_encoding = False\n",
    "split_size = (0.8, 0.0, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 24 duplicate rows.\n",
      "Dropped 2588 rows -> height too low.\n",
      "Dropped 1 rows -> height too high.\n",
      "Dropped 13 rows -> weight too low.\n",
      "Dropped 0 rows -> weight too high.\n",
      "Dropped 183 rows -> systolic bp too low.\n",
      "Dropped 46 rows -> systolic bp too high.\n",
      "Dropped 38 rows -> diastolic bp too low.\n",
      "Dropped 904 rows -> diastolic bp too high.\n",
      "Dropped 98 rows -> sytolic bp was lower than diastolic.\n",
      "0        normal\n",
      "1          high\n",
      "2        normal\n",
      "3          high\n",
      "4        normal\n",
      "          ...  \n",
      "69995    normal\n",
      "69996      high\n",
      "69997      high\n",
      "69998    normal\n",
      "69999    normal\n",
      "Name: ap_lo_cat, Length: 66105, dtype: category\n",
      "Categories (3, object): ['low' < 'normal' < 'high']\n",
      "0        normal\n",
      "1          high\n",
      "2          high\n",
      "3          high\n",
      "4        normal\n",
      "          ...  \n",
      "69995    normal\n",
      "69996      high\n",
      "69997      high\n",
      "69998      high\n",
      "69999    normal\n",
      "Name: ap_hi_cat, Length: 66105, dtype: category\n",
      "Categories (3, object): ['low' < 'normal' < 'high']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besitzer\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:201: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
     ]
    }
   ],
   "source": [
    "#apply get_data function\n",
    "y_train, x_train, y_val, x_val, y_test, x_test = get_data(enable_feature_engineering_gender, enable_feature_engineering_height_weight, enable_feature_engineering_gluc_chol, enable_feature_engineering_alco_smoking, enable_outlier_handling, normalize, use_one_hot_encoding, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>active</th>\n",
       "      <th>is_female</th>\n",
       "      <th>bmi</th>\n",
       "      <th>unhealthy_lifestyle</th>\n",
       "      <th>ap_lo_cat</th>\n",
       "      <th>ap_hi_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69890</th>\n",
       "      <td>0.840186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>0.347735</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.821758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13426</th>\n",
       "      <td>0.812156</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>0.869919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39326</th>\n",
       "      <td>0.749903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>0.402865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58087</th>\n",
       "      <td>0.705149</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0.923268</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16712</th>\n",
       "      <td>0.809446</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52884 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  cholesterol  gluc  active  is_female  bmi  \\\n",
       "69890  0.840186            1     1    True      False    0   \n",
       "38013  0.347735            2     1    True       True    0   \n",
       "317    0.821758            1     1    True       True    0   \n",
       "13426  0.812156            1     3    True       True    0   \n",
       "4774   0.869919            1     1   False       True    0   \n",
       "...         ...          ...   ...     ...        ...  ...   \n",
       "39326  0.749903            1     1    True       True    0   \n",
       "6631   0.402865            1     1    True      False    0   \n",
       "58087  0.705149            1     1   False       True    0   \n",
       "913    0.923268            1     2    True      False    0   \n",
       "16712  0.809446            3     3    True       True    0   \n",
       "\n",
       "       unhealthy_lifestyle ap_lo_cat ap_hi_cat  \n",
       "69890                False      high      high  \n",
       "38013                False    normal    normal  \n",
       "317                  False    normal    normal  \n",
       "13426                False    normal    normal  \n",
       "4774                 False      high      high  \n",
       "...                    ...       ...       ...  \n",
       "39326                False    normal    normal  \n",
       "6631                 False      high      high  \n",
       "58087                False    normal      high  \n",
       "913                  False    normal      high  \n",
       "16712                False    normal    normal  \n",
       "\n",
       "[52884 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    float64\n",
       "cholesterol              int64\n",
       "gluc                     int64\n",
       "active                    bool\n",
       "is_female                 bool\n",
       "bmi                      int64\n",
       "unhealthy_lifestyle       bool\n",
       "ap_lo_cat               object\n",
       "ap_hi_cat               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'high'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ad60b221877e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnaive_bayes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnaive_bayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'high'"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the model (predict)\n",
    "y_prob = naive_bayes.predict(x_test)\n",
    "y_pred = np.round(y_prob)\n",
    "y_proba = naive_bayes.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(y_test, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "method_name = 'Naïve Bayes'\n",
    "predicted_probabilities = y_proba\n",
    "savePredictedProbabilities(method_name, y_test, predicted_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
